{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Input, LeakyReLU, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Đọc DataFrame 'transaction'\n",
    "transaction_df = pd.read_csv('../balanced_transaction-from-to-prefix-22-KLTN-newtime.csv')\n",
    "\n",
    "# # Tạo DataFrame 'data' để lưu kết quả\n",
    "# data_df = pd.DataFrame(columns=['hash', 'image', 'label'])\n",
    "\n",
    "# # Đọc cột 'hash' và 'label'\n",
    "# hash_values = transaction_df['hash']\n",
    "# label_values = transaction_df['label']\n",
    "\n",
    "# # Khởi tạo biến đếm\n",
    "# loop_counter = 1\n",
    "\n",
    "# # Duyệt qua từng giá trị hash và label\n",
    "# for hash_value, label_value in zip(hash_values, label_values):\n",
    "#     # Tạo tên file từ giá trị hash\n",
    "#     filename = f'./dataset/x30/data/_{hash_value}_data.txt'\n",
    "\n",
    "#     try:\n",
    "#         # Đọc nội dung từ file\n",
    "#         data = np.genfromtxt(filename, delimiter='\\t')\n",
    "#         # image = pd.read_csv(filename)\n",
    "\n",
    "#         # Kiểm tra kích thước mảng\n",
    "#         if data.shape == (30, 30):\n",
    "#             # Tạo một hàng mới trong DataFrame 'data'\n",
    "#             new_row = pd.DataFrame({'hash': [hash_value], 'image': [data], 'label': [label_value]})\n",
    "#             data_df = pd.concat([data_df, new_row], ignore_index=True)\n",
    "#         else:\n",
    "#             print(f\"Kích thước mảng không phù hợp trong file {filename}\")\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"Không tìm thấy file {filename}\")\n",
    "\n",
    "#     # In ra lần chạy thứ n của vòng lặp\n",
    "#     print(f\"Lần chạy thứ {loop_counter}\")\n",
    "#     loop_counter += 1\n",
    "\n",
    "#     # if loop_counter == 4:\n",
    "#     #   break\n",
    "\n",
    "# # In ra DataFrame 'data'\n",
    "# print(data_df.shape)\n",
    "# print(data_df.head(3))\n",
    "\n",
    "# image_arrays = data_df['image'].tolist()\n",
    "\n",
    "# # Tạo numpy array từ danh sách các mảng 2D\n",
    "# np_images = np.stack(image_arrays, axis=0)\n",
    "# # Chia dữ liệu thành tập huấn luyện và tập kiểm tra\n",
    "# X_train, X_test, y_train, y_test = train_test_split(data_df['image'].values, data_df['label'].values, test_size=0.1, random_state=42)\n",
    "# print(type(X_train))\n",
    "# print(type(y_train))\n",
    "\n",
    "# # Required Libraries\n",
    "# from keras.models import Model\n",
    "# from keras.layers import Input, Dense, Conv2D, LeakyReLU, Dropout, Flatten, Lambda, Activation, Reshape, Conv2DTranspose, Conv1DTranspose, Conv1D\n",
    "# # from keras.utils.vis_utils import plot_model\n",
    "# from keras.datasets.mnist import load_data\n",
    "# from keras import backend as K\n",
    "# from tensorflow.keras.optimizers import Adam\n",
    "# from numpy.random import randn, randint\n",
    "# from numpy import expand_dims, zeros, ones, asarray\n",
    "# from matplotlib import pyplot\n",
    "\n",
    "# # load the images\n",
    "# def load_real_samples():\n",
    "#     # (trainX, trainy), (_, _) = load_data()\n",
    "#     trainX, _, trainy, _ = train_test_split(np_images, data_df['label'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "#     # print(trainX.shape, trainy.shape)\n",
    "#     # print(type(trainX))\n",
    "#     # print(trainX[0])\n",
    "#     # print(type(trainX[0][0]))\n",
    "#     # print(type(trainy))\n",
    "#     # print(trainy[2])\n",
    "#     X = expand_dims(trainX, axis=-1)\n",
    "#     X = X.astype('float32')\n",
    "#     trainy = trainy.astype('uint8')\n",
    "#     X = (X - 127.5) / 127.5  # scale from [0,255] to [-1,1] as we will be using tanh activation.\n",
    "\n",
    "#     # Convert pandas to numpy for trainy\n",
    "#     # trainy = trainy.values\n",
    "#     # print(X[0])\n",
    "#     # print(type(X))\n",
    "#     # print(X.shape, trainy.shape)\n",
    "#     return [X, trainy]\n",
    "\n",
    "# data = load_real_samples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 420
    },
    "id": "UbVW8CFChRd4",
    "outputId": "457276e3-db2e-4627-b94e-fa81bb851757"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.81037152e-02 2.89604821e-01 9.90888919e-02 1.64745564e-01\n",
      "  1.98023835e-02 3.52191235e-01 1.03305785e-01 5.09593767e-06\n",
      "  1.23760689e-03 5.17312733e-04 7.93691456e-23 6.21459592e-04\n",
      "  9.58204334e-02 4.86963579e-03 8.27284011e-04 1.96981912e-02\n",
      "  0.00000000e+00 4.91450481e-04 4.80016893e-04 2.89604736e-01\n",
      "  3.77547433e-07 0.00000000e+00 1.11242759e-01 2.89604824e-01\n",
      "  1.02923700e-01 3.70677520e-01 4.82081161e-03 3.87484641e-02\n",
      "  2.49713870e-03 5.04349160e-06]\n",
      " [2.53652007e-05 2.92663004e-05 0.00000000e+00 7.31399700e-04\n",
      "  2.50379056e-01 6.41445215e-03 2.38282480e-03 4.80286476e-02\n",
      "  3.03030303e-21 9.88033052e-04 3.65578858e-04 2.89604736e-01\n",
      "  3.16621317e-07 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "######### Convert manual #########\n",
    "# Chuyển đổi DataFrame thành mảng NumPy\n",
    "\n",
    "replace_nan = transaction_df.replace(np.nan, -1)\n",
    "\n",
    "X = replace_nan.drop(columns=['hash','from_address','to_address','label'], axis=1).values\n",
    "\n",
    "# Padding giá trị -2 để có số lượng đặc trưng là bội số của 49\n",
    "num_padding = 900 - X.shape[1] % 900\n",
    "X_padded = np.pad(X, ((0, 0), (0, num_padding)), mode='constant', constant_values=-2)\n",
    "\n",
    "# Tiền xử lý dữ liệu\n",
    "scaler = MinMaxScaler()\n",
    "normalized_data = scaler.fit_transform(X_padded)\n",
    "\n",
    "# Reshape mảng thành ma trận 3 chiều 4x4\n",
    "X_reshaped = normalized_data.reshape(-1, 30, 30)\n",
    "\n",
    "print(X_reshaped[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required Libraries\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Conv2D, LeakyReLU, Dropout, Flatten, Lambda, Activation, Reshape, Conv2DTranspose, Conv1DTranspose, Conv1D\n",
    "# from keras.utils.vis_utils import plot_model\n",
    "from keras.datasets.mnist import load_data\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from numpy.random import randn, randint\n",
    "from numpy import expand_dims, zeros, ones, asarray\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test select\n",
      "[15795   860  5390 ... 19446  2336  9879]\n",
      "[ 572 7521 6171 ... 6470 2062 9030]\n"
     ]
    }
   ],
   "source": [
    "# (train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, transaction_df['label'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalize pixel values to be between 0 and 1\n",
    "# train_images, test_images = train_images / 255.0, test_images / 255.0\n",
    "\n",
    "# # Normalize Train\n",
    "# train_images = expand_dims(train_images, axis=-1)\n",
    "# train_images = train_images.astype('float32')\n",
    "# train_labels = train_labels.astype('uint8')\n",
    "# train_images = train_images / 255.0\n",
    "\n",
    "# Normalize Test\n",
    "X_test = expand_dims(X_test, axis=-1)\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('uint8')\n",
    "# test_images = test_images / 255.0\n",
    "\n",
    "def load_real_samples(n_classes=10):\n",
    "    # (trainX, trainy), (_, _) = load_data()\n",
    "    trainX, _, trainy, _ = train_test_split(X_reshaped, transaction_df['label'].values, test_size=0.2, random_state=42)\n",
    "\n",
    "    # print(trainX.shape, trainy.shape)\n",
    "    # print(type(trainX))\n",
    "    # print(trainX[0])\n",
    "    # print(type(trainX[0][0]))\n",
    "    # print(type(trainy))\n",
    "    # print(trainy[2])\n",
    "    X = expand_dims(trainX, axis=-1)\n",
    "    X = X.astype('float32')\n",
    "    trainy = trainy.astype('uint8')\n",
    "    # scale from [0,255] to [0,1] as we will be using tanh activation.\n",
    "#     X = X / 255.0  \n",
    "\n",
    "    # Convert pandas to numpy for trainy\n",
    "    # trainy = trainy.values\n",
    "    # print(X[0])\n",
    "    # print(type(X))\n",
    "    # print(X.shape, trainy.shape)\n",
    "    return [X, trainy]\n",
    "\n",
    "def select_supervised_samples(dataset, n_samples=5000, n_classes=2):\n",
    " \tprint('test select')\n",
    " \tX, y = dataset\n",
    " \tX_list, y_list = list(), list()\n",
    " \tn_per_class = int(n_samples / n_classes) #Number of amples per class.\n",
    " \tfor i in range(n_classes):\n",
    "         X_with_class = X[y == i] # get all images for this class\n",
    "         ix = np.random.randint(0, len(X_with_class), n_per_class) # choose random images for each class\n",
    "         print(ix)\n",
    "         [X_list.append(X_with_class[j]) for j in ix] # add to list\n",
    "         [y_list.append(i) for j in ix]\n",
    " \treturn asarray(X_list), asarray(y_list) #Returns a list of 2 numpy arrays corresponding to X and Y\n",
    "\n",
    "dataset = load_real_samples()\n",
    "X_train, y_train = select_supervised_samples(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pnzc_yzXkInv",
    "outputId": "fbfce6ee-e22e-49dd-b901-729f6dc36ec9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay object at 0x00000267E1DD2450>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pptph\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\optimizers\\legacy\\adam.py:117: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "#Initializing model\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "#Adding the model layers\n",
    "model.add(keras.layers.LSTM(128, input_shape=(30, 30), return_sequences=True))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.LSTM(128))\n",
    "model.add(keras.layers.Dense(64, activation='relu'))\n",
    "model.add(keras.layers.Dropout(0.2))\n",
    "model.add(keras.layers.Dense(2, activation='softmax'))\n",
    "\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.9)\n",
    "print(lr_schedule)\n",
    "\n",
    "#Compiling the model\n",
    "model.compile( loss='sparse_categorical_crossentropy', optimizer = keras.optimizers.Adam(lr=0.0001), metrics=['accuracy'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0791 - accuracy: 0.9760\n",
      "Epoch 2/100\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0724 - accuracy: 0.9776\n",
      "Epoch 3/100\n",
      "157/157 [==============================] - 4s 26ms/step - loss: 0.0692 - accuracy: 0.9782\n",
      "Epoch 4/100\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.0691 - accuracy: 0.9798\n",
      "Epoch 5/100\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0713 - accuracy: 0.9790\n",
      "Epoch 6/100\n",
      "157/157 [==============================] - 5s 30ms/step - loss: 0.0819 - accuracy: 0.9744\n",
      "Epoch 7/100\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0772 - accuracy: 0.9780\n",
      "Epoch 8/100\n",
      "157/157 [==============================] - 4s 29ms/step - loss: 0.0645 - accuracy: 0.9810\n",
      "Epoch 9/100\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0729 - accuracy: 0.9766\n",
      "Epoch 10/100\n",
      "157/157 [==============================] - 4s 27ms/step - loss: 0.0876 - accuracy: 0.9720\n",
      "Epoch 11/100\n",
      "157/157 [==============================] - 5s 29ms/step - loss: 0.0686 - accuracy: 0.9796\n",
      "Epoch 12/100\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.0773 - accuracy: 0.9754\n",
      "Epoch 13/100\n",
      "157/157 [==============================] - 4s 28ms/step - loss: 0.0705 - accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "# Tạo đối tượng EarlyStopping\n",
    "early_stop = EarlyStopping(monitor='accuracy', patience=5, restore_best_weights=True)\n",
    "\n",
    "#Fitting data to the model\n",
    "history = model.fit(X_train, y_train, epochs=100, callbacks=[early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "jjJj2Yvnl2CZ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "297/297 [==============================] - 3s 10ms/step\n",
      "Thời gian thực thi: 3227342.80 micro giây\n",
      "y_pred:  [1 1 0 ... 0 1 0]\n",
      "y_test:  [1 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "import time\n",
    "# Lấy thời gian bắt đầu\n",
    "start_time = time.perf_counter()\n",
    "\n",
    "y_pred=model.predict(X_test)\n",
    "\n",
    "# Lấy thời gian kết thúc\n",
    "end_time = time.perf_counter()\n",
    "# Tính thời gian thực thi (đơn vị: giây)\n",
    "execution_time = end_time - start_time\n",
    "# Chuyển đơi sang đơn vị micro giây\n",
    "execution_time_microseconds = execution_time * 1000000\n",
    "print(f\"Thời gian thực thi: {execution_time_microseconds:.2f} micro giây\")\n",
    "\n",
    "y_pred=np.argmax(y_pred,axis=1)\n",
    "# y_pred = np.round(abs(disc_sup_trained_model.predict_step(X_test)))\n",
    "print('y_pred: ', y_pred)\n",
    "print('y_test: ', y_test)\n",
    "y_pred = y_pred.astype('uint8')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix\n",
      "----------------------------------------------\n",
      "accuracy\n",
      "0.973033\n",
      "racall\n",
      "0.964744\n",
      "precision\n",
      "0.976367\n",
      "f1score\n",
      "0.970520\n"
     ]
    }
   ],
   "source": [
    "# Print evaluation metrics\n",
    "print(\"confusion matrix\")\n",
    "print(\"----------------------------------------------\")\n",
    "print(\"accuracy\")\n",
    "print(\"%.6f\" % accuracy)\n",
    "print(\"racall\")\n",
    "print(\"%.6f\" % recall)\n",
    "print(\"precision\")\n",
    "print(\"%.6f\" % precision)\n",
    "print(\"f1score\")\n",
    "print(\"%.6f\" % f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dương tính giả (false positive rate): 0.0199\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "\n",
    "# Tính toán dương tính giả (false positive rate)\n",
    "fpr = fp / (fp + tn)\n",
    "\n",
    "print(f\"Dương tính giả (false positive rate): {fpr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_layer_call_fn, lstm_cell_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Result-ML/final/lstm-5000\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./Result-ML/final/lstm-5000\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('./Result-ML/final/lstm-5000',save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "194/194 [==============================] - 4s 22ms/step\n",
      "194/194 [==============================] - 4s 22ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 4s 20ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 18ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 4s 22ms/step\n",
      "194/194 [==============================] - 5s 26ms/step\n",
      "194/194 [==============================] - 4s 21ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 18ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 18ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 4s 18ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 17ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 4s 19ms/step\n",
      "194/194 [==============================] - 3s 18ms/step\n",
      "194/194 [==============================] - 3s 18ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 13ms/step\n",
      "194/194 [==============================] - 3s 13ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 16ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 13ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 14ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 15ms/step\n",
      "194/194 [==============================] - 3s 13ms/step\n",
      "[93.68947708198839, 93.4151065203357, 93.91542930923175, 93.77017430600387, 94.22207876049063, 93.49580374435119, 93.96384764364106, 93.67333763718528, 94.38347320852162, 93.94770819883796, 93.73789541639768, 93.64105874757908, 93.97998708844416, 94.01226597805035, 94.52872821174951, 93.70561652679147, 93.99612653324726, 93.60877985797289, 94.51258876694641, 93.624919302776, 93.94770819883796, 93.85087153001936, 93.75403486120078, 94.09296320206585, 94.09296320206585, 93.67333763718528, 94.41575209812783, 93.80245319561007, 93.52808263395738, 94.51258876694641, 93.86701097482246, 93.99612653324726, 93.49580374435119, 94.7385409941898, 93.91542930923175, 93.99612653324726, 93.38282763072951, 93.89928986442865, 93.47966429954809, 93.56036152356359, 93.94770819883796, 93.46352485474499, 93.3989670755326, 93.93156875403487, 93.60877985797289, 94.28663653970304, 94.07682375726274, 94.28663653970304, 93.93156875403487, 93.93156875403487, 93.67333763718528, 94.02840542285345, 94.17366042608134, 93.60877985797289, 93.91542930923175, 93.97998708844416, 93.85087153001936, 93.73789541639768, 93.3666881859264, 93.86701097482246, 94.36733376371853, 93.80245319561007, 93.78631375080697, 93.88315041962557, 93.94770819883796, 93.85087153001936, 93.83473208521626, 93.624919302776, 93.85087153001936, 93.56036152356359, 93.77017430600387, 93.57650096836669, 93.83473208521626, 93.88315041962557, 94.18979987088444, 93.97998708844416, 94.07682375726274, 93.83473208521626, 93.49580374435119, 93.72175597159458, 94.51258876694641, 93.26985151710781, 94.07682375726274, 93.64105874757908, 94.14138153647514, 94.20593931568753, 93.64105874757908, 94.14138153647514, 93.64105874757908, 93.99612653324726, 94.23821820529373, 94.09296320206585, 94.14138153647514, 93.5119431891543, 93.26985151710781, 94.17366042608134, 93.3989670755326, 93.75403486120078, 93.77017430600387, 93.47966429954809]\n"
     ]
    }
   ],
   "source": [
    "test_list = list()\n",
    "\n",
    "for i in range (0,100):\n",
    "    _, X_test, _, y_test = train_test_split(np_images, data_df['label'].values, test_size=0.2, random_state=i)\n",
    "    \n",
    "    # expand to 3d, e.g. add channels\n",
    "    X_test = expand_dims(X_test, axis=-1)\n",
    "\n",
    "    # convert from ints to floats\n",
    "    X_test = X_test.astype('float32')\n",
    "    y_test = y_test.astype('uint8')\n",
    "\n",
    "    # scale from [0,255] to [-1,1]\n",
    "    X_test = X_test / 255.0\n",
    "    \n",
    "    y_pred=model.predict(X_test)\n",
    "    y_pred=np.argmax(y_pred,axis=1)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    test_list.append(accuracy * 100)\n",
    "#     if accuracy * 100 < 85:\n",
    "#         test_list.append(i)\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
